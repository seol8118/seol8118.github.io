---
title: "Introduction"
date: 2020-08-20
category:
  - RL
tag :
  - RL
sidebar:
  nav: sidebar-rl
mathjax: "true"
author_profile: false
toc: true
toc_label: "Contents"
toc_icon: "cog"
toc_sticky: true
header:
  overlay_image: /assets/images/dataScience.jpg
  overlay_filter: 0.5
comments: true  
---
 
> ML study > Reinforcement Learning > Introduction

<script type="text/javascript" 
src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML">
</script>


<center><img src="/assets/images/rl/alpha.jpg" width="60%"  ></center>

[<center>Source</center>](http://m.dongascience.donga.com/news.php?idx=10919)

- 2016년 바둑에서 컴퓨터가 사람을 이길 수 없을 것이라는 대다수의 여론에도 불구하고 알파고는 이세돌과의 대국에서 4:1 이라는 스코어로 대승을 거둔다. 이 후 강화학습에 대한 굉장히 많은 연구들이 이루어졌으며 현재는 바둑과 같은 게임 뿐 아니라 로봇, 자율주행 등에 다양하게 적용되고 있다. 그렇다면 이 강화학습이란 어떤 기술인지 차근차근 살펴보자. 

## 1. Machine learning 종류
### 1.1 Supervised learning : 정답이 있는 데이터 학습
### 1.2 Unsupervised learning : 정답이 없는 데이터 학습
### 1.3 Reinforcement learning : 보상으로 부터 학습

- 이와 같이 Machin learning은 크게 3가지로 구분할 수 있다. Image classification과 같이 정답이 있는 데이터로 학습을 하는 경우 supervised learning, Clustering과 같이 정답이 없는 데이터로 부터 학습을 하는 경우는 unsupervised learning, 정답은 없지만 보상으로는 것이 있어서 그것으로 부터 학습하는 방식을 Reinforcement learning 이라고 한다. 

## 2. Reinforcement learning
<center><img src="/assets/images/rl/mouse.jpg"  width="60%" ></center>

[<center>Source</center>](https://namu.wiki/w/%ED%96%89%EB%8F%99%EC%A3%BC%EC%9D%98)


- 위 그림과 같이 쥐 한마리를 작은 상자에 넣어 놓고 어떤 버튼을 눌렀을 때 간식이 나오는 환경이 있다고 하자. 쥐가 처음에는 상자안을 돌아다니다가 어쩌다 버튼을 누르게 되고 간식을 먹게될 것이다. 그렇게 시간이 흐르면 쥐는 버튼은 누르면 간식이 나온다는 사실을 학습하게 되고 배가 고플때마다 버튼을 눌러 간식을 먹을 것이다. 이러한 과정이 바로 강화학습이다.

<center><img src="/assets/images/rl/rlGraph.jpg"  width="60%" ></center>

- 앞선 경우를 일반화하여 도식화하면 위 그림과 같다. Agent(쥐)가 어떤 action(버튼을 누름) 을 했을 때 환경으로 부터 보상(간식)을 받게 되고 다음 스텝에서 동일한 과정이 반복된다. 이로써 agent는 학습이 가능해지고 이것이 가장 직관적인 형태의 강화학습이라고 할 수 있다.


## Reference
\[1]: [Reinforcement learning: an introduction](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)

\[2]: [Fundamental of Reinforcement Learning](https://dnddnjs.gitbooks.io/rl)
